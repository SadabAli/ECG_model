{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cce8898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simpal\n"
     ]
    }
   ],
   "source": [
    "print('simpal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "731a1d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f6ede7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = r'D:\\ECG_model\\multiple lead\\ecg_images_multilead'\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63417313",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for cls in range(1, 10):  # class_1 → class_9\n",
    "    class_dir = os.path.join(BASE_DIR, f\"class_{cls}\")\n",
    "    for f in os.listdir(class_dir):\n",
    "        image_paths.append(os.path.join(class_dir, f))\n",
    "        labels.append(cls - 1)  # 0–8\n",
    "\n",
    "image_paths = np.array(image_paths)\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97583cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_map = defaultdict(list)\n",
    "\n",
    "for i, path in enumerate(image_paths):\n",
    "    ecg_id = os.path.basename(path).split(\"_win\")[0]\n",
    "    ecg_map[ecg_id].append(i)\n",
    "\n",
    "ecg_ids = list(ecg_map.keys())\n",
    "\n",
    "train_ecg, temp_ecg = train_test_split(ecg_ids, test_size=0.3, random_state=42)\n",
    "val_ecg, test_ecg = train_test_split(temp_ecg, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13dceda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect(ecg_list):\n",
    "    idx = []\n",
    "    for e in ecg_list:\n",
    "        idx.extend(ecg_map[e])\n",
    "    return idx\n",
    "\n",
    "train_idx = collect(train_ecg)\n",
    "val_idx   = collect(val_ecg)\n",
    "test_idx  = collect(test_ecg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59da929a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage1_label(l):\n",
    "    return 0 if l == 0 else 1   # 0=Normal, 1=Abnormal\n",
    "\n",
    "y_stage1 = np.array([stage1_label(l) for l in labels])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6085dd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path, label):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    img = tf.keras.applications.efficientnet.preprocess_input(img)\n",
    "    return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42142307",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = image_paths[train_idx], y_stage1[train_idx]\n",
    "X_val,   y_val   = image_paths[val_idx],   y_stage1[val_idx]\n",
    "X_test,  y_test  = image_paths[test_idx],  y_stage1[test_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "285076fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_ds = train_ds.map(load_image).shuffle(1000).batch(BATCH_SIZE)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "val_ds = val_ds.map(load_image).batch(BATCH_SIZE)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "test_ds = test_ds.map(load_image).batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "695dfaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = EfficientNetB0(include_top=False, weights=\"imagenet\",\n",
    "                      input_shape=(224,224,3))\n",
    "base.trainable = False\n",
    "\n",
    "inputs = layers.Input(shape=(224,224,3))\n",
    "x = base(inputs, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "stage1_model = models.Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b268cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage1_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f943deac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1086/1086 [==============================] - 145s 96ms/step - loss: 0.3945 - accuracy: 0.8400 - val_loss: 0.3484 - val_accuracy: 0.8597\n",
      "Epoch 2/30\n",
      "1086/1086 [==============================] - 103s 95ms/step - loss: 0.3045 - accuracy: 0.8867 - val_loss: 0.3371 - val_accuracy: 0.8660\n",
      "Epoch 3/30\n",
      "1086/1086 [==============================] - 105s 96ms/step - loss: 0.2940 - accuracy: 0.8906 - val_loss: 0.3346 - val_accuracy: 0.8659\n",
      "Epoch 4/30\n",
      "1086/1086 [==============================] - 105s 97ms/step - loss: 0.2892 - accuracy: 0.8892 - val_loss: 0.3293 - val_accuracy: 0.8675\n",
      "Epoch 5/30\n",
      "1086/1086 [==============================] - 103s 95ms/step - loss: 0.2835 - accuracy: 0.8916 - val_loss: 0.3297 - val_accuracy: 0.8672\n",
      "Epoch 6/30\n",
      "1086/1086 [==============================] - 103s 95ms/step - loss: 0.2812 - accuracy: 0.8929 - val_loss: 0.3267 - val_accuracy: 0.8684\n",
      "Epoch 7/30\n",
      "1086/1086 [==============================] - 104s 95ms/step - loss: 0.2780 - accuracy: 0.8946 - val_loss: 0.3247 - val_accuracy: 0.8694\n",
      "Epoch 8/30\n",
      "1086/1086 [==============================] - 103s 95ms/step - loss: 0.2751 - accuracy: 0.8950 - val_loss: 0.3242 - val_accuracy: 0.8695\n",
      "Epoch 9/30\n",
      "1086/1086 [==============================] - 104s 96ms/step - loss: 0.2724 - accuracy: 0.8962 - val_loss: 0.3214 - val_accuracy: 0.8719\n",
      "Epoch 10/30\n",
      "1086/1086 [==============================] - 104s 96ms/step - loss: 0.2704 - accuracy: 0.8970 - val_loss: 0.3218 - val_accuracy: 0.8716\n",
      "Epoch 11/30\n",
      "1086/1086 [==============================] - 104s 96ms/step - loss: 0.2705 - accuracy: 0.8960 - val_loss: 0.3211 - val_accuracy: 0.8718\n",
      "Epoch 12/30\n",
      "1086/1086 [==============================] - 104s 95ms/step - loss: 0.2673 - accuracy: 0.8969 - val_loss: 0.3213 - val_accuracy: 0.8716\n",
      "Epoch 13/30\n",
      "1086/1086 [==============================] - 104s 95ms/step - loss: 0.2657 - accuracy: 0.8974 - val_loss: 0.3213 - val_accuracy: 0.8711\n",
      "Epoch 14/30\n",
      "1086/1086 [==============================] - 104s 95ms/step - loss: 0.2660 - accuracy: 0.8976 - val_loss: 0.3232 - val_accuracy: 0.8702\n",
      "Epoch 15/30\n",
      "1086/1086 [==============================] - 104s 95ms/step - loss: 0.2655 - accuracy: 0.8986 - val_loss: 0.3202 - val_accuracy: 0.8719\n",
      "Epoch 16/30\n",
      "1086/1086 [==============================] - 104s 96ms/step - loss: 0.2636 - accuracy: 0.8988 - val_loss: 0.3223 - val_accuracy: 0.8700\n",
      "Epoch 17/30\n",
      "1086/1086 [==============================] - 104s 96ms/step - loss: 0.2620 - accuracy: 0.8996 - val_loss: 0.3180 - val_accuracy: 0.8724\n",
      "Epoch 18/30\n",
      "1086/1086 [==============================] - 104s 95ms/step - loss: 0.2628 - accuracy: 0.8991 - val_loss: 0.3217 - val_accuracy: 0.8722\n",
      "Epoch 19/30\n",
      "1086/1086 [==============================] - 104s 96ms/step - loss: 0.2614 - accuracy: 0.8988 - val_loss: 0.3217 - val_accuracy: 0.8715\n",
      "Epoch 20/30\n",
      "1086/1086 [==============================] - 104s 96ms/step - loss: 0.2615 - accuracy: 0.8993 - val_loss: 0.3235 - val_accuracy: 0.8699\n",
      "Epoch 21/30\n",
      "1086/1086 [==============================] - 104s 96ms/step - loss: 0.2597 - accuracy: 0.8996 - val_loss: 0.3209 - val_accuracy: 0.8707\n",
      "Epoch 22/30\n",
      "1086/1086 [==============================] - 104s 96ms/step - loss: 0.2585 - accuracy: 0.9004 - val_loss: 0.3183 - val_accuracy: 0.8735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f90b00a6a0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage1_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=5, restore_best_weights=True)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5d27b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "win_preds = []\n",
    "win_true  = []\n",
    "\n",
    "for imgs, labs in test_ds:\n",
    "    preds = stage1_model.predict(imgs, verbose=0)\n",
    "    win_preds.extend(np.argmax(preds, axis=1))\n",
    "    win_true.extend(labs.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78399ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_preds = defaultdict(list)\n",
    "ecg_true = {}\n",
    "\n",
    "for path, p, t in zip(X_test, win_preds, win_true):\n",
    "    ecg_id = os.path.basename(path).split(\"_win\")[0]\n",
    "    ecg_preds[ecg_id].append(p)\n",
    "    ecg_true[ecg_id] = t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "574512bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = []\n",
    "final_true = []\n",
    "\n",
    "for e in ecg_preds:\n",
    "    final_pred.append(max(set(ecg_preds[e]), key=ecg_preds[e].count))\n",
    "    final_true.append(ecg_true[e])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c41c8a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAGE-1 ECG Accuracy: 0.8515037593984962\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.875     0.154     0.262        91\n",
      "           1      0.851     0.995     0.917       441\n",
      "\n",
      "    accuracy                          0.852       532\n",
      "   macro avg      0.863     0.575     0.590       532\n",
      "weighted avg      0.855     0.852     0.805       532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"STAGE-1 ECG Accuracy:\",\n",
    "      accuracy_score(final_true, final_pred))\n",
    "print(classification_report(final_true, final_pred, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39bddfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal_ecgs = [e for e in ecg_preds if ecg_true[e] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc6df222",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage2_paths = []\n",
    "stage2_labels = []\n",
    "\n",
    "for e in abnormal_ecgs:\n",
    "    for idx in ecg_map[e]:\n",
    "        stage2_paths.append(image_paths[idx])\n",
    "        stage2_labels.append(labels[idx] - 1)  # shift (remove normal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb315878",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage2_paths = np.array(stage2_paths)\n",
    "stage2_labels = np.array(stage2_labels)\n",
    "NUM_STAGE2_CLASSES = len(np.unique(stage2_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ebe48f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "    stage2_paths, stage2_labels,\n",
    "    test_size=0.3, random_state=42, stratify=stage2_labels\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "afd22e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "train2_ds = tf.data.Dataset.from_tensor_slices((X_tr, y_tr))\n",
    "train2_ds = train2_ds.map(load_image).shuffle(1000).batch(BATCH_SIZE)\n",
    "\n",
    "test2_ds = tf.data.Dataset.from_tensor_slices((X_te, y_te))\n",
    "test2_ds = test2_ds.map(load_image).batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae37df42",
   "metadata": {},
   "outputs": [],
   "source": [
    "base2 = EfficientNetB0(include_top=False, weights=\"imagenet\",\n",
    "                       input_shape=(224,224,3))\n",
    "base2.trainable = False\n",
    "\n",
    "inputs = layers.Input(shape=(224,224,3))\n",
    "x = base2(inputs, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "outputs = layers.Dense(NUM_STAGE2_CLASSES, activation=\"softmax\")(x)\n",
    "\n",
    "stage2_model = models.Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a840b7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage2_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632cdf9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "136/136 [==============================] - 15s 81ms/step - loss: 2.2375 - accuracy: 0.1902\n",
      "Epoch 2/30\n",
      "136/136 [==============================] - 11s 80ms/step - loss: 1.9020 - accuracy: 0.3011\n",
      "Epoch 3/30\n",
      "136/136 [==============================] - 11s 80ms/step - loss: 1.7689 - accuracy: 0.3566\n",
      "Epoch 4/30\n",
      "136/136 [==============================] - 11s 80ms/step - loss: 1.6797 - accuracy: 0.3913\n",
      "Epoch 5/30\n",
      "136/136 [==============================] - 11s 80ms/step - loss: 1.6143 - accuracy: 0.4203\n",
      "Epoch 6/30\n",
      "136/136 [==============================] - 11s 81ms/step - loss: 1.5665 - accuracy: 0.4358\n",
      "Epoch 7/30\n",
      "136/136 [==============================] - 11s 81ms/step - loss: 1.5219 - accuracy: 0.4582\n",
      "Epoch 8/30\n",
      "136/136 [==============================] - 11s 80ms/step - loss: 1.4799 - accuracy: 0.4784\n",
      "Epoch 9/30\n",
      "136/136 [==============================] - 11s 80ms/step - loss: 1.4489 - accuracy: 0.4848\n",
      "Epoch 10/30\n",
      "136/136 [==============================] - 11s 81ms/step - loss: 1.4234 - accuracy: 0.4934\n",
      "Epoch 11/30\n",
      "136/136 [==============================] - 11s 82ms/step - loss: 1.3970 - accuracy: 0.5047\n",
      "Epoch 12/30\n",
      "136/136 [==============================] - 11s 81ms/step - loss: 1.3715 - accuracy: 0.5161\n",
      "Epoch 13/30\n",
      "136/136 [==============================] - 11s 81ms/step - loss: 1.3543 - accuracy: 0.5270\n",
      "Epoch 14/30\n",
      "136/136 [==============================] - 11s 81ms/step - loss: 1.3304 - accuracy: 0.5249\n",
      "Epoch 15/30\n",
      "136/136 [==============================] - 11s 81ms/step - loss: 1.3080 - accuracy: 0.5402\n",
      "Epoch 16/30\n",
      "136/136 [==============================] - 11s 81ms/step - loss: 1.2916 - accuracy: 0.5381\n",
      "Epoch 17/30\n",
      "136/136 [==============================] - 11s 82ms/step - loss: 1.2696 - accuracy: 0.5478\n",
      "Epoch 18/30\n",
      "136/136 [==============================] - 11s 81ms/step - loss: 1.2608 - accuracy: 0.5626\n",
      "Epoch 19/30\n",
      "136/136 [==============================] - 11s 81ms/step - loss: 1.2512 - accuracy: 0.5545\n",
      "Epoch 20/30\n",
      "136/136 [==============================] - 11s 81ms/step - loss: 1.2367 - accuracy: 0.5633\n",
      "Epoch 21/30\n",
      "136/136 [==============================] - 11s 80ms/step - loss: 1.2256 - accuracy: 0.5677\n",
      "Epoch 22/30\n",
      "136/136 [==============================] - 11s 81ms/step - loss: 1.2086 - accuracy: 0.5739\n",
      "Epoch 23/30\n",
      "136/136 [==============================] - 11s 81ms/step - loss: 1.2036 - accuracy: 0.5714\n",
      "Epoch 24/30\n",
      "136/136 [==============================] - 11s 81ms/step - loss: 1.1951 - accuracy: 0.5793\n",
      "Epoch 25/30\n",
      "136/136 [==============================] - 11s 81ms/step - loss: 1.1801 - accuracy: 0.5844\n",
      "Epoch 26/30\n",
      "136/136 [==============================] - 11s 81ms/step - loss: 1.1719 - accuracy: 0.5862\n",
      "Epoch 27/30\n",
      "136/136 [==============================] - 11s 81ms/step - loss: 1.1578 - accuracy: 0.5950\n",
      "Epoch 28/30\n",
      "136/136 [==============================] - 11s 81ms/step - loss: 1.1533 - accuracy: 0.5931\n",
      "Epoch 29/30\n",
      "136/136 [==============================] - 11s 81ms/step - loss: 1.1373 - accuracy: 0.5957\n",
      "Epoch 30/30\n",
      "136/136 [==============================] - 11s 81ms/step - loss: 1.1299 - accuracy: 0.6031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fa322d5940>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage2_model.fit(\n",
    "    train2_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"loss\", patience=5, restore_best_weights=True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2ffb8454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAGE-2 ECG Accuracy: 0.6100917431192661\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.729     0.775     0.752        80\n",
      "           1      0.535     0.479     0.505        48\n",
      "           2      0.600     0.643     0.621        14\n",
      "           3      0.530     0.892     0.665       120\n",
      "           4      0.724     0.404     0.519        52\n",
      "           5      0.640     0.320     0.427        50\n",
      "           6      0.727     0.414     0.527        58\n",
      "           7      1.000     0.286     0.444        14\n",
      "\n",
      "    accuracy                          0.610       436\n",
      "   macro avg      0.686     0.527     0.557       436\n",
      "weighted avg      0.646     0.610     0.592       436\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# ===============================\n",
    "# STAGE-2 WINDOW-LEVEL PREDICTION\n",
    "# ===============================\n",
    "win_preds_2 = []\n",
    "win_true_2  = []\n",
    "win_paths_2 = []\n",
    "\n",
    "for imgs, labs in test2_ds:\n",
    "    preds = stage2_model.predict(imgs, verbose=0)\n",
    "    win_preds_2.extend(np.argmax(preds, axis=1))\n",
    "    win_true_2.extend(labs.numpy())\n",
    "\n",
    "# collect corresponding paths\n",
    "win_paths_2 = X_te  # SAME ORDER as test2_ds creation\n",
    "\n",
    "# ===============================\n",
    "# AGGREGATE TO ECG-LEVEL\n",
    "# ===============================\n",
    "ecg_preds_2 = defaultdict(list)\n",
    "ecg_true_2  = {}\n",
    "\n",
    "for path, p, t in zip(win_paths_2, win_preds_2, win_true_2):\n",
    "    ecg_id = os.path.basename(path).split(\"_win\")[0]\n",
    "    ecg_preds_2[ecg_id].append(p)\n",
    "    ecg_true_2[ecg_id] = t\n",
    "\n",
    "final_pred_2 = []\n",
    "final_true_2 = []\n",
    "\n",
    "for e in ecg_preds_2:\n",
    "    # majority voting (same as Stage-1)\n",
    "    final_pred_2.append(\n",
    "        max(set(ecg_preds_2[e]), key=ecg_preds_2[e].count)\n",
    "    )\n",
    "    final_true_2.append(ecg_true_2[e])\n",
    "\n",
    "final_pred_2 = np.array(final_pred_2)\n",
    "final_true_2 = np.array(final_true_2)\n",
    "\n",
    "# ===============================\n",
    "# FINAL STAGE-2 ECG REPORT\n",
    "# ===============================\n",
    "print(\"STAGE-2 ECG Accuracy:\",\n",
    "      accuracy_score(final_true_2, final_pred_2))\n",
    "\n",
    "print(classification_report(\n",
    "    final_true_2,\n",
    "    final_pred_2,\n",
    "    digits=3\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f744e607",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e5ace0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.signal import stft\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from collections import defaultdict\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras import layers, models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f550ac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = r'D:\\ECG_model\\Data'        # folder containing A0001.mat ...\n",
    "CSV_PATH = r'D:\\ECG_model\\REFERENCE.csv'           # Recording, First_label\n",
    "IMG_DIR = \"ecg_images_multilead\"\n",
    "\n",
    "FS = 500                          # sampling frequency\n",
    "FIXED_LEN = 7500                  # 15 sec\n",
    "WINDOW = 1000                     # 2 sec\n",
    "STRIDE = 500                      # 50% overlap\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "NUM_CLASSES = 9\n",
    "\n",
    "LEADS = [0, 1, 2]   # Lead-1, Lead-2, Lead-3 (0-indexed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8541c282",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "label_map = {\n",
    "    row[\"Recording\"]: row[\"First_label\"] - 1   # map 1–9 → 0–8\n",
    "    for _, row in labels_df.iterrows()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eed695cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_length(sig, length=7500):\n",
    "    if sig.shape[0] >= length:\n",
    "        return sig[:length]\n",
    "    else:\n",
    "        return np.pad(sig, (0, length - sig.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a1fe3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_image(signal):\n",
    "    f, t, Zxx = stft(signal, fs=FS, nperseg=128)\n",
    "    img = np.abs(Zxx)\n",
    "    img = (img - img.min()) / (img.max() - img.min() + 1e-8)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f7e0bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(IMG_DIR, exist_ok=True)\n",
    "\n",
    "for cls in range(NUM_CLASSES):\n",
    "    os.makedirs(os.path.join(IMG_DIR, f\"class_{cls+1}\"), exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb761ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in os.listdir(DATA_DIR):\n",
    "\n",
    "    rec_id = fname.replace(\".mat\", \"\")\n",
    "    if rec_id not in label_map:\n",
    "        continue\n",
    "\n",
    "    label = label_map[rec_id]\n",
    "\n",
    "    mat = sio.loadmat(os.path.join(DATA_DIR, fname))\n",
    "    ecg = mat[\"ECG\"][0][0][\"data\"]     # shape (12, N)\n",
    "\n",
    "    # select leads\n",
    "    leads = [fix_length(ecg[l]) for l in LEADS]\n",
    "\n",
    "    # windowing\n",
    "    win_id = 0\n",
    "    for start in range(0, FIXED_LEN - WINDOW + 1, STRIDE):\n",
    "\n",
    "        channels = []\n",
    "        for sig in leads:\n",
    "            w = sig[start:start + WINDOW]\n",
    "            img = tf_image(w)\n",
    "            channels.append(img)\n",
    "\n",
    "        # stack → RGB\n",
    "        rgb = np.stack(channels, axis=-1)\n",
    "\n",
    "        # resize\n",
    "        rgb = tf.image.resize(rgb, IMG_SIZE).numpy()\n",
    "\n",
    "        # save\n",
    "        save_path = os.path.join(\n",
    "            IMG_DIR,\n",
    "            f\"class_{label+1}\",\n",
    "            f\"{rec_id}_win{win_id}.png\"\n",
    "        )\n",
    "\n",
    "        plt.imsave(save_path, rgb)\n",
    "        win_id += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64f4ab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"ecg_train_multilead\"\n",
    "val_dir   = \"ecg_val_multilead\"\n",
    "test_dir  = \"ecg_test_multilead\"\n",
    "\n",
    "for d in [train_dir, val_dir, test_dir]:\n",
    "    for c in range(NUM_CLASSES):\n",
    "        os.makedirs(os.path.join(d, f\"class_{c+1}\"), exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1537f6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_groups = defaultdict(list)\n",
    "\n",
    "for cls in range(NUM_CLASSES):\n",
    "    class_dir = os.path.join(IMG_DIR, f\"class_{cls+1}\")\n",
    "    for f in os.listdir(class_dir):\n",
    "        ecg_id = f.split(\"_win\")[0]\n",
    "        ecg_groups[(ecg_id, cls)].append(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62656ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecgs = list(ecg_groups.keys())\n",
    "train_ecg, temp = train_test_split(ecgs, test_size=0.3, random_state=42)\n",
    "val_ecg, test_ecg = train_test_split(temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92e50e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_ecgs(ecg_list, target_dir):\n",
    "    for ecg_id, cls in ecg_list:\n",
    "        for img in ecg_groups[(ecg_id, cls)]:\n",
    "            src = os.path.join(IMG_DIR, f\"class_{cls+1}\", img)\n",
    "            dst = os.path.join(target_dir, f\"class_{cls+1}\", img)\n",
    "            tf.io.gfile.copy(src, dst, overwrite=True)\n",
    "\n",
    "copy_ecgs(train_ecg, train_dir)\n",
    "copy_ecgs(val_ecg, val_dir)\n",
    "copy_ecgs(test_ecg, test_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f332e9",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3de4f8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 34734 files belonging to 9 classes.\n",
      "Found 7448 files belonging to 9 classes.\n",
      "Found 7448 files belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    val_dir,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6649f569",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = EfficientNetB0(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:200]:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd465b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=(224,224,3))\n",
    "x = tf.keras.applications.efficientnet.preprocess_input(inputs)\n",
    "x = base_model(x)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "\n",
    "model = models.Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bb0e60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea932657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1086/1086 [==============================] - 131s 107ms/step - loss: 2.2557 - accuracy: 0.2478 - val_loss: 2.0109 - val_accuracy: 0.3467\n",
      "Epoch 2/30\n",
      "1086/1086 [==============================] - 116s 107ms/step - loss: 1.9047 - accuracy: 0.3564 - val_loss: 1.8773 - val_accuracy: 0.3835\n",
      "Epoch 3/30\n",
      "1086/1086 [==============================] - 116s 107ms/step - loss: 1.7651 - accuracy: 0.4041 - val_loss: 1.8057 - val_accuracy: 0.4017\n",
      "Epoch 4/30\n",
      "1086/1086 [==============================] - 117s 108ms/step - loss: 1.6769 - accuracy: 0.4274 - val_loss: 1.7600 - val_accuracy: 0.4137\n",
      "Epoch 5/30\n",
      "1086/1086 [==============================] - 120s 110ms/step - loss: 1.6021 - accuracy: 0.4541 - val_loss: 1.7265 - val_accuracy: 0.4240\n",
      "Epoch 6/30\n",
      "1086/1086 [==============================] - 121s 111ms/step - loss: 1.5501 - accuracy: 0.4667 - val_loss: 1.7044 - val_accuracy: 0.4300\n",
      "Epoch 7/30\n",
      "1086/1086 [==============================] - 122s 112ms/step - loss: 1.5064 - accuracy: 0.4836 - val_loss: 1.6874 - val_accuracy: 0.4392\n",
      "Epoch 8/30\n",
      "1086/1086 [==============================] - 122s 112ms/step - loss: 1.4749 - accuracy: 0.4934 - val_loss: 1.6725 - val_accuracy: 0.4447\n",
      "Epoch 9/30\n",
      "1086/1086 [==============================] - 120s 111ms/step - loss: 1.4417 - accuracy: 0.5039 - val_loss: 1.6630 - val_accuracy: 0.4503\n",
      "Epoch 10/30\n",
      "1086/1086 [==============================] - 121s 111ms/step - loss: 1.4095 - accuracy: 0.5147 - val_loss: 1.6518 - val_accuracy: 0.4529\n",
      "Epoch 11/30\n",
      "1086/1086 [==============================] - 122s 112ms/step - loss: 1.3881 - accuracy: 0.5210 - val_loss: 1.6462 - val_accuracy: 0.4553\n",
      "Epoch 12/30\n",
      "1086/1086 [==============================] - 123s 113ms/step - loss: 1.3597 - accuracy: 0.5297 - val_loss: 1.6485 - val_accuracy: 0.4588\n",
      "Epoch 13/30\n",
      "1086/1086 [==============================] - 122s 112ms/step - loss: 1.3383 - accuracy: 0.5370 - val_loss: 1.6485 - val_accuracy: 0.4600\n",
      "Epoch 14/30\n",
      "1086/1086 [==============================] - 122s 112ms/step - loss: 1.3119 - accuracy: 0.5468 - val_loss: 1.6552 - val_accuracy: 0.4573\n",
      "Epoch 15/30\n",
      "1086/1086 [==============================] - 121s 112ms/step - loss: 1.2981 - accuracy: 0.5516 - val_loss: 1.6522 - val_accuracy: 0.4613\n",
      "Epoch 16/30\n",
      "1086/1086 [==============================] - 121s 111ms/step - loss: 1.2749 - accuracy: 0.5591 - val_loss: 1.6526 - val_accuracy: 0.4620\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27b67750550>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=30,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=5,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d9153c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "file_paths = test_ds.file_paths\n",
    "\n",
    "for imgs, labels in test_ds:\n",
    "    preds = model.predict(imgs, verbose=0)\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n",
    "    y_true.extend(labels.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbb24487",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_preds = defaultdict(list)\n",
    "ecg_true = {}\n",
    "\n",
    "for path, p, t in zip(file_paths, y_pred, y_true):\n",
    "    ecg_id = os.path.basename(path).split(\"_win\")[0]\n",
    "    ecg_preds[ecg_id].append(p)\n",
    "    ecg_true[ecg_id] = t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a61c8dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = []\n",
    "final_true = []\n",
    "\n",
    "for ecg_id in ecg_preds:\n",
    "    pred = max(set(ecg_preds[ecg_id]), key=ecg_preds[ecg_id].count)\n",
    "    final_pred.append(pred)\n",
    "    final_true.append(ecg_true[ecg_id])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6dea7e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECG-Level Accuracy: 0.5112781954887218\n",
      "\n",
      "ECG-Level Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.43      0.51        91\n",
      "           1       0.63      0.75      0.69        80\n",
      "           2       0.40      0.44      0.42        48\n",
      "           3       0.60      0.64      0.62        14\n",
      "           4       0.48      0.83      0.61       122\n",
      "           5       0.20      0.04      0.06        52\n",
      "           6       0.57      0.16      0.25        51\n",
      "           7       0.46      0.52      0.49        60\n",
      "           8       0.14      0.07      0.10        14\n",
      "\n",
      "    accuracy                           0.51       532\n",
      "   macro avg       0.46      0.43      0.42       532\n",
      "weighted avg       0.49      0.51      0.47       532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"ECG-Level Accuracy:\", accuracy_score(final_true, final_pred))\n",
    "\n",
    "print(\"\\nECG-Level Classification Report:\\n\")\n",
    "print(classification_report(\n",
    "    final_true,\n",
    "    final_pred,\n",
    "    labels=list(range(9)),\n",
    "    digits=2\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0de6132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECG-Level Accuracy: 0.5338345864661654\n",
      "\n",
      "ECG-Level Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.48      0.56        91\n",
      "           1       0.62      0.74      0.67        80\n",
      "           2       0.43      0.48      0.46        48\n",
      "           3       0.59      0.71      0.65        14\n",
      "           4       0.53      0.80      0.64       122\n",
      "           5       0.33      0.08      0.12        52\n",
      "           6       0.65      0.22      0.32        51\n",
      "           7       0.41      0.57      0.48        60\n",
      "           8       0.17      0.07      0.10        14\n",
      "\n",
      "    accuracy                           0.53       532\n",
      "   macro avg       0.49      0.46      0.44       532\n",
      "weighted avg       0.53      0.53      0.50       532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Collect per-window probabilities\n",
    "probs = []\n",
    "y_true = []\n",
    "file_paths = test_ds.file_paths\n",
    "\n",
    "for images, labels in test_ds:\n",
    "    p = model.predict(images, verbose=0)  # shape (B, 9)\n",
    "    probs.extend(p)\n",
    "    y_true.extend(labels.numpy())\n",
    "\n",
    "# Group by ECG id\n",
    "ecg_probs = defaultdict(list)\n",
    "ecg_true = {}\n",
    "\n",
    "for path, p, t in zip(file_paths, probs, y_true):\n",
    "    ecg_id = os.path.basename(path).split(\"_win\")[0]\n",
    "    ecg_probs[ecg_id].append(p)\n",
    "    ecg_true[ecg_id] = t\n",
    "\n",
    "# Average probabilities per ECG\n",
    "final_pred = []\n",
    "final_true = []\n",
    "\n",
    "for ecg_id, plist in ecg_probs.items():\n",
    "    avg_p = np.mean(plist, axis=0)\n",
    "    final_pred.append(np.argmax(avg_p))\n",
    "    final_true.append(ecg_true[ecg_id])\n",
    "\n",
    "print(\"ECG-Level Accuracy:\", accuracy_score(final_true, final_pred))\n",
    "print(\"\\nECG-Level Classification Report:\\n\")\n",
    "print(classification_report(final_true, final_pred, labels=list(range(9)), digits=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8aa0b0",
   "metadata": {},
   "source": [
    "### Merging week class -> abnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4d9aea8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = r'D:\\ECG_model\\multiple lead\\ecg_images_multilead'   # FULL multi-lead image folder\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 35\n",
    "\n",
    "# original labels: 0–8 (from class_1 → class_9)\n",
    "# merge: class 5 + class 8 → new class 5\n",
    "NUM_CLASSES = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f475cecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total window images: 49630\n"
     ]
    }
   ],
   "source": [
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for cls in range(1, 10):  # class_1 → class_9\n",
    "    class_dir = os.path.join(BASE_DIR, f\"class_{cls}\")\n",
    "    for fname in os.listdir(class_dir):\n",
    "        image_paths.append(os.path.join(class_dir, fname))\n",
    "        labels.append(cls - 1)   # map 1–9 → 0–8\n",
    "\n",
    "image_paths = np.array(image_paths)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(\"Total window images:\", len(image_paths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "99907ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap_label(l):\n",
    "    if l == 8:\n",
    "        return 5\n",
    "    return l\n",
    "\n",
    "labels = np.array([remap_label(l) for l in labels])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e3c7fc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_to_indices = defaultdict(list)\n",
    "\n",
    "for i, path in enumerate(image_paths):\n",
    "    ecg_id = os.path.basename(path).split(\"_win\")[0]\n",
    "    ecg_to_indices[ecg_id].append(i)\n",
    "\n",
    "ecg_ids = list(ecg_to_indices.keys())\n",
    "\n",
    "train_ecg, temp_ecg = train_test_split(ecg_ids, test_size=0.3, random_state=42)\n",
    "val_ecg, test_ecg = train_test_split(temp_ecg, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "32a46c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_indices(ecg_list):\n",
    "    idx = []\n",
    "    for e in ecg_list:\n",
    "        idx.extend(ecg_to_indices[e])\n",
    "    return idx\n",
    "\n",
    "train_idx = collect_indices(train_ecg)\n",
    "val_idx   = collect_indices(val_ecg)\n",
    "test_idx  = collect_indices(test_ecg)\n",
    "\n",
    "X_train, y_train = image_paths[train_idx], labels[train_idx]\n",
    "X_val,   y_val   = image_paths[val_idx],   labels[val_idx]\n",
    "X_test,  y_test  = image_paths[test_idx],  labels[test_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f9138796",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path, label):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    img = tf.keras.applications.efficientnet.preprocess_input(img)\n",
    "    return img, label\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_ds = train_ds.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_ds = train_ds.shuffle(1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "val_ds = val_ds.map(load_image).batch(BATCH_SIZE)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "test_ds = test_ds.map(load_image).batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d85af65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = EfficientNetB0(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "# fine-tuning\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:200]:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7be19f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=(224, 224, 3))\n",
    "x = base_model(inputs, training=True)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "\n",
    "model = models.Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f9441851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "1086/1086 [==============================] - 132s 118ms/step - loss: 2.1312 - accuracy: 0.2704 - val_loss: 2.1743 - val_accuracy: 0.2505\n",
      "Epoch 2/35\n",
      "1086/1086 [==============================] - 129s 119ms/step - loss: 1.8189 - accuracy: 0.3621 - val_loss: 2.0848 - val_accuracy: 0.2662\n",
      "Epoch 3/35\n",
      "1086/1086 [==============================] - 129s 118ms/step - loss: 1.6848 - accuracy: 0.4085 - val_loss: 2.0131 - val_accuracy: 0.2956\n",
      "Epoch 4/35\n",
      "1086/1086 [==============================] - 127s 117ms/step - loss: 1.6111 - accuracy: 0.4324 - val_loss: 1.9825 - val_accuracy: 0.3006\n",
      "Epoch 5/35\n",
      "1086/1086 [==============================] - 127s 117ms/step - loss: 1.5504 - accuracy: 0.4473 - val_loss: 1.9635 - val_accuracy: 0.3091\n",
      "Epoch 6/35\n",
      "1086/1086 [==============================] - 127s 117ms/step - loss: 1.5090 - accuracy: 0.4635 - val_loss: 1.9512 - val_accuracy: 0.3056\n",
      "Epoch 7/35\n",
      "1086/1086 [==============================] - 127s 116ms/step - loss: 1.4670 - accuracy: 0.4806 - val_loss: 1.9413 - val_accuracy: 0.3150\n",
      "Epoch 8/35\n",
      "1086/1086 [==============================] - 128s 117ms/step - loss: 1.4286 - accuracy: 0.4902 - val_loss: 1.9259 - val_accuracy: 0.3200\n",
      "Epoch 9/35\n",
      "1086/1086 [==============================] - 125s 114ms/step - loss: 1.3979 - accuracy: 0.5063 - val_loss: 1.9260 - val_accuracy: 0.3214\n",
      "Epoch 10/35\n",
      "1086/1086 [==============================] - 126s 116ms/step - loss: 1.3723 - accuracy: 0.5153 - val_loss: 1.9172 - val_accuracy: 0.3218\n",
      "Epoch 11/35\n",
      "1086/1086 [==============================] - 122s 112ms/step - loss: 1.3480 - accuracy: 0.5209 - val_loss: 1.9174 - val_accuracy: 0.3251\n",
      "Epoch 12/35\n",
      "1086/1086 [==============================] - 115s 106ms/step - loss: 1.3264 - accuracy: 0.5287 - val_loss: 1.9247 - val_accuracy: 0.3224\n",
      "Epoch 13/35\n",
      "1086/1086 [==============================] - 114s 105ms/step - loss: 1.3081 - accuracy: 0.5347 - val_loss: 1.9298 - val_accuracy: 0.3304\n",
      "Epoch 14/35\n",
      "1086/1086 [==============================] - 114s 105ms/step - loss: 1.2835 - accuracy: 0.5450 - val_loss: 1.9284 - val_accuracy: 0.3276\n",
      "Epoch 15/35\n",
      "1086/1086 [==============================] - 115s 106ms/step - loss: 1.2723 - accuracy: 0.5458 - val_loss: 1.9139 - val_accuracy: 0.3346\n",
      "Epoch 16/35\n",
      "1086/1086 [==============================] - 115s 105ms/step - loss: 1.2477 - accuracy: 0.5556 - val_loss: 1.9321 - val_accuracy: 0.3289\n",
      "Epoch 17/35\n",
      "1086/1086 [==============================] - 114s 105ms/step - loss: 1.2337 - accuracy: 0.5629 - val_loss: 1.9363 - val_accuracy: 0.3327\n",
      "Epoch 18/35\n",
      "1086/1086 [==============================] - 114s 105ms/step - loss: 1.2196 - accuracy: 0.5666 - val_loss: 1.9257 - val_accuracy: 0.3371\n",
      "Epoch 19/35\n",
      "1086/1086 [==============================] - 114s 104ms/step - loss: 1.2006 - accuracy: 0.5749 - val_loss: 1.9422 - val_accuracy: 0.3350\n",
      "Epoch 20/35\n",
      "1086/1086 [==============================] - 115s 106ms/step - loss: 1.1883 - accuracy: 0.5787 - val_loss: 1.9436 - val_accuracy: 0.3410\n",
      "Epoch 21/35\n",
      "1086/1086 [==============================] - 117s 107ms/step - loss: 1.1751 - accuracy: 0.5839 - val_loss: 1.9450 - val_accuracy: 0.3353\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27d0c02a760>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=6,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "259ab3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "for imgs, labs in test_ds:\n",
    "    preds = model.predict(imgs, verbose=0)\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n",
    "    y_true.extend(labs.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a89b28b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_preds = defaultdict(list)\n",
    "ecg_true = {}\n",
    "\n",
    "for path, p, t in zip(X_test, y_pred, y_true):\n",
    "    ecg_id = os.path.basename(path).split(\"_win\")[0]\n",
    "    ecg_preds[ecg_id].append(p)\n",
    "    ecg_true[ecg_id] = t\n",
    "\n",
    "final_pred = []\n",
    "final_true = []\n",
    "\n",
    "for ecg_id in ecg_preds:\n",
    "    pred = max(set(ecg_preds[ecg_id]), key=ecg_preds[ecg_id].count)\n",
    "    final_pred.append(pred)\n",
    "    final_true.append(ecg_true[ecg_id])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ee6c8870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECG-Level Accuracy: 0.3966165413533835\n",
      "\n",
      "ECG-Level Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.36      0.42        91\n",
      "           1       0.54      0.55      0.54        80\n",
      "           2       0.35      0.25      0.29        48\n",
      "           3       1.00      0.14      0.25        14\n",
      "           4       0.35      0.80      0.48       122\n",
      "           5       0.22      0.03      0.05        66\n",
      "           6       0.47      0.14      0.21        51\n",
      "           7       0.33      0.23      0.27        60\n",
      "\n",
      "    accuracy                           0.40       532\n",
      "   macro avg       0.47      0.31      0.32       532\n",
      "weighted avg       0.41      0.40      0.35       532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"ECG-Level Accuracy:\",\n",
    "      accuracy_score(final_true, final_pred))\n",
    "\n",
    "print(\"\\nECG-Level Classification Report:\\n\")\n",
    "\n",
    "print(classification_report(\n",
    "    final_true,\n",
    "    final_pred,\n",
    "    labels=list(range(NUM_CLASSES)),\n",
    "    digits=2\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304d57bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
